{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I. Функция, вычленяющая 'Окончание ссылки для итерации постоянной итерации'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_link_pattern(inital_url):\n",
    "    '''Функция возвращает ссылку, на следующую страницу (next) содержащую новости'''\n",
    "    \n",
    "    response = requests.get(inital_url).text\n",
    "\n",
    "    html_structure = BeautifulSoup(response, 'html.parser')\n",
    "\n",
    "    next_button = html_structure.findAll('a', class_= 'btn lenta_pager_next') #Содержит HTML-тэг, в формате строки\n",
    "\n",
    "    pattern = r\"\\?down=\\d+\"\n",
    "\n",
    "    try:\n",
    "        return re.findall(pattern, str(next_button[0]))[0]\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "II. Цикл, формирующий список, состоящий из всех страниц новостей по конкретной тематике"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_url = 'https://vtomske.ru/tag/economics' #Начальная ссылка\n",
    "\n",
    "string_to_be_formatted = 'https://vtomske.ru/tag/economics{}'\n",
    "\n",
    "links_list = []\n",
    "\n",
    "links_list.append(initial_url)\n",
    "\n",
    "#while len(links_list) <= 5000:\n",
    "while True:\n",
    "\n",
    "    next_pattern = extract_link_pattern(initial_url) #Переменная содержит в себе паттерн продолжения\n",
    "\n",
    "    #print(next_pattern)\n",
    "\n",
    "    if next_pattern == 0:\n",
    "        break #Цикл прекращается, если на странице отсутсвует кнопка 'Раньше' == Новости по тематике закончились.\n",
    "\n",
    "    next_link = string_to_be_formatted.format(next_pattern) #Форматируем строку - ссылку, добавляя в нее продолжение\n",
    "\n",
    "    links_list.append(next_link) #Сохраняем ссылку в список ссылок\n",
    "\n",
    "    initial_url = next_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_link_list(initial_url):\n",
    "    '''Функция получает начальную ссылку на новостную тематику с сайта vtomske.ru в след. формате:\n",
    "    https://vtomske.ru/tag/russia\n",
    "    И возвращает список ссылок на все страницы новостей по данной новостной тематике.'''\n",
    "    \n",
    "    #string_to_be_formatted = 'https://vtomske.ru/tag/economics{}'\n",
    "    string_to_be_formatted = f\"{initial_url}{{}}\"\n",
    "\n",
    "    links_list = []\n",
    "\n",
    "    links_list.append(initial_url)\n",
    "\n",
    "#while len(links_list) <= 5000:\n",
    "    while True:\n",
    "        next_pattern = extract_link_pattern(initial_url) #Переменная содержит в себе паттерн продолжения\n",
    "\n",
    "        if next_pattern == 0:\n",
    "            break #Цикл прекращается, если на странице отсутсвует кнопка 'Раньше' == Новости по тематике закончились.\n",
    "\n",
    "        next_link = string_to_be_formatted.format(next_pattern) #Форматируем строку - ссылку, добавляя в нее продолжение\n",
    "\n",
    "        links_list.append(next_link) #Сохраняем ссылку в список ссылок\n",
    "\n",
    "        initial_url = next_link\n",
    "\n",
    "    return links_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "III. Попытка получать именно новости с ссылок"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Опишем функцию для получения ссылок на конкретные новости со страницы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_news_links(url):\n",
    "    '''Функция, позволяющая извлечь список URL для всех новостей, находящихся на странице.\n",
    "    Возвращает список (python list), состоящий из завершенных URL'''\n",
    "    response = requests.get(url).text\n",
    "\n",
    "    soup = BeautifulSoup(response, 'html.parser')\n",
    "\n",
    "    raw_list = soup.findAll('a', class_=\"lenta_material\") #Содержит в список, из которого следует извлечь ссылку на новость\n",
    "\n",
    "    extract_pattern = r'href=\"(.*?)\"' #паттерн регулярного выражения, позволяющий выделить окончание новости\n",
    "\n",
    "    urls_final_list = []\n",
    "\n",
    "    for tag in raw_list:\n",
    "        \n",
    "        tag = str(tag)\n",
    "\n",
    "        result = re.findall(extract_pattern, tag)\n",
    "\n",
    "        urls_final_list.append(result[0])\n",
    "\n",
    "    return urls_final_list\n",
    "    #return link_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IV. Отлично, извлекаем заголовок и текст новости из новости"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_title_and_text(news_url):\n",
    "    '''Функция извлекает следующий аспекты из новостной статьи:\n",
    "    1. Новостной заголовок.\n",
    "    2. Текст новостной статьи.\n",
    "    3. Дату публикации.\n",
    "    4. Тэги.\n",
    "    На вход получает ссылку на конкретную новость.'''\n",
    "\n",
    "    start_link = 'https://vtomske.ru'\n",
    "\n",
    "    full_link_url = start_link + news_url\n",
    "\n",
    "    beautiful_html_structure = BeautifulSoup(requests.get(full_link_url).text, 'html.parser')\n",
    "\n",
    "    headline = beautiful_html_structure.findAll('h1')[0]\n",
    "\n",
    "    article_text = beautiful_html_structure.findAll('p')\n",
    "\n",
    "    #Извлечение даты\n",
    "\n",
    "    publication_date = beautiful_html_structure.findAll('time', class_=\"material-date\")\n",
    "\n",
    "    date_pattern = r'\\d{4}-\\d{2}-\\d{2}'\n",
    "\n",
    "    date = re.findall(date_pattern, str(publication_date))[0]\n",
    "\n",
    "    #/Извлечение даты\n",
    "\n",
    "    #Извлечение тегов\n",
    "\n",
    "    tags_raw = beautiful_html_structure.findAll('div', class_=\"material-tags\")\n",
    "\n",
    "    tags_pattern = r\">\\w+<\"\n",
    "\n",
    "    tags = re.findall(tags_pattern, str(tags_raw))\n",
    "\n",
    "    for index in range(0, len(tags)):\n",
    "        tags[index] = tags[index].replace(\">\", \"\").replace(\"<\", \"\")\n",
    "\n",
    "    #/Излвечение тэгов\n",
    "\n",
    "    #Возвращаем результат\n",
    "\n",
    "    final_dict = {\n",
    "        'Заголовок': str(headline),\n",
    "        'Текст новости': str(article_text),\n",
    "        'Дата публикации': str(date),\n",
    "        'Тэги': str(tags)\n",
    "    }\n",
    "    \n",
    "    return final_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VI. Опишем функцию парсинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(theme_url):\n",
    "    '''Функция, осуществляющая парсинг конкретной тематике с сайта vtomske.ru.\n",
    "    Ссылка должна вести на существующую тематику и иметь ввиду, типа:\n",
    "    https://vtomske.ru/tag/russia\n",
    "    Возвращает датафрейм и сохраняет его в активную директорию'''\n",
    "    news_pages = form_link_list(theme_url)\n",
    "\n",
    "    print(f\"По выбранной тематике на сайте представлено {len(news_pages)} страниц новостей\")\n",
    "\n",
    "    print('Процесс сбора новостей запущен...\\nПрогресс обработки страниц:')\n",
    "\n",
    "    information_list = [] #Лист, содержащий в себе информацию по каждой новости\n",
    "\n",
    "    for page in tqdm(news_pages):\n",
    "        news_list = extract_news_links(page) #Список, содержащий в себе ссылки на конкретные новости с одной страницы.\n",
    "\n",
    "        for news in news_list:\n",
    "            news_info = extract_title_and_text(news)\n",
    "            information_list.append(news_info)\n",
    "    \n",
    "    final_df = pd.DataFrame(information_list)\n",
    "\n",
    "    final_df.to_csv(f'all_news_for_{theme_url}.csv')\n",
    "\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_link = 'https://vtomske.ru/tag/economics'\n",
    "\n",
    "new_df = parse(test_link)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_news",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
