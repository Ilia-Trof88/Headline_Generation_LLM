# Генерация новостных заголовков с использованием современных языковых моделей

## О проекте

Данный проект представляет собой современную реализацию и развитие идей, представленных в магистерской диссертации:

> Трофимов И. П. Дообучение нейросети ruGPT-3 для генерации новостных заголовков: формальная оценка влияния новостной рубрики на качество заголовка: магистерская диссертация по направлению подготовки: 45.04.03 - Фундаментальная и прикладная лингвистика / Трофимов И. П., Рахимова З. Я. - Томск, 2024. URL: https://vital.lib.tsu.ru/vital/access/manager/Repository/vital:22017 

Оригинальное исследование фокусировалось на использовании модели ruGPT-3 для генерации новостных заголовков для новостных текстов различных тематик, в то время как данный проект адаптирует методологию с применением современных больших языковых моделей (LLM) с открытым исходным кодом. Это позволяет не только проверить актуальность первоначальных выводов, но и исследовать новые возможности в задаче генерации новостных заголовков.

## Основные отличия от оригинального исследования

- Использование современных больших языковых моделей (LLM) с открым исходным кодом:
  - Gemma-2-2B (4-bit квантование)
  - Gemma-2-9B (4-bit квантование)
  - Mistral-Nemo (4-bit квантование)
  Все модели используется в квантованной версии (4 бита) для оптимизации использования вычислительных ресурсов в условиях ограниченных вычислительных мощностей. 
- Добавление метрики оценивания семантической близости (BertScore).
- Удаление метрики METEOR.

## Результаты

### Zero-shot генерация

| Модель | BertScore |  |  | BLEU | ROUGE-1 | ROUGE-2 | ROUGE-L |
|:-------|:---------:|:--------:|:--------:|:-----:|:--------:|:--------:|:--------:|
| | P | R | F1 | | | | |
|Gemma-2-2b (4-bit) | 0.70 | 0.68 | 0.64 | 0.00029 | 0.10 | 0.03 | 0.08 |
|Gemma-2-9b (4-bit) | 0.70 | 0.75 | 0.72 | 0.00038 | 0.22 | 0.11 | 0.20 |
|Mistral-Nemo (4-bit) | 0.72 | 0.76 | 0.74 | 0.00074 | 0.24 | 0.11 | 0.22 |

### После дообучения (Fine-tuning)

| Модель | BertScore |  |  | BLEU | ROUGE-1 | ROUGE-2 | ROUGE-L |
|:-------|:---------:|:--------:|:--------:|:-----:|:--------:|:--------:|:--------:|
| | P | R | F1 | | | | |
|Gemma-2-2b (4-bit) | 0.77 | 0.77 | 0.77 | 0.00079 | 0.31 | 0.16 | 0.29 |
|Gemma-2-9b (4-bit) | 0.79 | 0.79 | 0.79 | 0.0008 | 0.36 | 0.21 | 0.34 |
|Mistral-Nemo (4-bit) | 0.79 | 0.79 | 0.79 | 0.00082 | 0.34 | 0.19 | 0.32 |

где:
- P - Precision (точность)
- R - Recall (полнота)
- F1 - F1-мера

Сравнение результатов показывает значительное улучшение показателей по всем метрикам после дообучения моделей. Особенно заметен прогресс в метриках ROUGE, где значения увеличились в среднем на 50%. BertScore также показал существенный рост, достигнув 0.79 для больших моделей.
Следует обратить внимание также на то, что после дообучения, качество генерации модели Gemma-2-2b почти сравнялось с результатами остальных моделей, что говорит об эффективности применении техники дообучения (Finetuning) для моделей с небольшим количеством параметров. Модель gemma2-2b в 4.5 раза меньше (по количеству параметров), чем gemma-2-9b и в 6 раз меньше, чем Mistral-Nemo.

## Структура проекта

Проект состоит из следующих директорий:
1. data_preprocessing.
  - Директория содержит в себе ноутбуке и скрипт для преобработки текстовых данных.
2. finetuning.
  - Директория содержит ноутбук, посвященный дообучения языковых моделей с использование библиотеки unsloth.
3. generation_evaluation.
  - Директория содержит ноутбук оценки результатов генерации (сгенерированных заголовков) больших языковых моделей.
    Была проведена оценка как Zero-Shot генерации, так и генерации дообученных моделей.
4. model_inference.
  - Директория содержит ноутбуки инференса (запуска) моделей.
5. parsing.
  - Директория содержит скрипт парсинга новостей с сайта новостного агентства vtomske.ru.

## Как использовать

Требования для запуска проекта:<br>
1. Установленные Anaconda или Miniconda
2. Git для клонирования репозитория

## Создание conda-окружения

1. Клонируйте данный репозиторий
```bash
git clone [https://github.com/Ilia-Trof88/Headline_Generation_LLM]
cd [название директории проекта]
```

2. Создайте conda-окружение из файла environment.yml:
```bash
conda env create -f environment.yml
```

3. Активируйте созданное окружение:
```bash
# Для Windows
conda activate [название_окружения]

# Для Linux/MacOS
source activate [название_окружения]
```
Однако из-за возможного конфликта версий CUDA и библиотеки torch, настоятельно рекомендуется создать новую среду, следуя инструкциям из официального репозитория библиотеки unsloth: https://github.com/unslothai/unsloth/tree/main#-installation-instructions

## Авторы оригинальной диссертации

1. Трофимов Илья Павлович. (Санкт-Петербургский государственный электротехнический университет «ЛЭТИ» им. В.И. Ульянова (Ленина), Национальный исследовательский Томский государственный университет)
2. Рахимова Зульфия Якубовна. (Национальный исследовательский Томский государственный университет)

## Автор данного проекта

1. Трофимов Илья Павлович.